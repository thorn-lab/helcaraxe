{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smooth_grad_prep.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l99SmnOYoBs5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tum3ajY0MpQj"
      },
      "source": [
        "load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boZ081oVoLDs"
      },
      "source": [
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/clean_Helcaraxe/Elenwe_Iobs_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa2dRBjEMrGs"
      },
      "source": [
        "Change the last layer from using a sigmoid function to use a softmax function. For this the last layer needs to be removed and replaced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tqSLG2noy2L"
      },
      "source": [
        "#Define input layer\n",
        "input = model.input\n",
        "#Remove the last layer\n",
        "model.layers.pop()\n",
        "#Define output layer\n",
        "class_layer = tf.keras.layers.Dense(2, activation='softmax', name=\"class_layer\")\n",
        "output = class_layer(model.layers[-1].output)\n",
        "#build new models with new output layer\n",
        "class_model = tf.keras.models.Model(inputs=input, outputs=[output])\n",
        "#compile new model\n",
        "OPTI = tf.keras.optimizers.Nadam(learning_rate=0.00001)\n",
        "class_model.compile(optimizer=OPTI,\n",
        "              loss=\"binary_crossentropy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uveTDexNNIGb"
      },
      "source": [
        "New model has to be trained very brief to connect the new layer to the old model. Therefore plots and models are prepared like in model_trainer.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2QU7U4idly1"
      },
      "source": [
        "#Get data for short and low retrain\n",
        "plots = np.load(\"/content/drive/MyDrive/clean_Helcaraxe/helcaraxe_elenwe_binplots_train.npy\")\n",
        "labels = np.load(\"/content/drive/MyDrive/clean_Helcaraxe/helcaraxe_elenwe_train_labels.npy\", allow_pickle=True)\n",
        "#Preprocess histograms\n",
        "resh_plots = plots.reshape(len(plots),80,80,1)\n",
        "resh_plots = tf.image.per_image_standardization(resh_plots)\n",
        "fin_plots = np.asarray(resh_plots).astype(np.float32)\n",
        "labels = np.asarray(labels).astype(np.float32)\n",
        "labels = tf.keras.utils.to_categorical(labels, num_classes=2)\n",
        "fin_plots = tf.convert_to_tensor(fin_plots)\n",
        "#Split sets\n",
        "train_size_lim = int((len(fin_plots)*0.8))\n",
        "train_plot =  fin_plots[:train_size_lim]\n",
        "val_plot = fin_plots[train_size_lim:]\n",
        "train_label = labels[:train_size_lim]\n",
        "val_label = labels[train_size_lim:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUmb1mzHd9Im"
      },
      "source": [
        "#Training preparations\n",
        "import os\n",
        "import datetime\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=12, restore_best_weights=True, monitor='val_loss', mode=\"min\")\n",
        "\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_cb = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"/content/drive/My Drive/Ice-ring\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYljKRl7eJeh",
        "outputId": "7303b6e2-bec8-4079-f148-f4eda810d0e4"
      },
      "source": [
        "#Train\n",
        "history = class_model.fit(train_plot, train_label,\n",
        "                    epochs=1,\n",
        "                    validation_data=(val_plot, val_label),\n",
        "                    callbacks=[early_stopping_cb, tensorboard_cb, model_checkpoint_cb]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "330/330 [==============================] - 52s 58ms/step - loss: 0.6856 - val_loss: 0.6900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSka2IchNZbH"
      },
      "source": [
        "save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5mNHykme_KG",
        "outputId": "af342154-332c-473a-aea6-d73e99629fcb"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/clean_Helcaraxe/class_model_elenwe_Iobs\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/clean_Helcaraxe/class_model_elenwe_Iobs/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}